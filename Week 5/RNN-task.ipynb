{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# set tf 1.x for colab\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    }
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Abagael',\n",
       " ' Abagail',\n",
       " ' Abbe',\n",
       " ' Abbey',\n",
       " ' Abbi',\n",
       " ' Abbie',\n",
       " ' Abby',\n",
       " ' Abigael',\n",
       " ' Abigail',\n",
       " ' Abigale',\n",
       " ' Abra',\n",
       " ' Acacia',\n",
       " ' Ada',\n",
       " ' Adah',\n",
       " ' Adaline',\n",
       " ' Adara',\n",
       " ' Addie',\n",
       " ' Addis',\n",
       " ' Adel',\n",
       " ' Adela',\n",
       " ' Adelaide',\n",
       " ' Adele',\n",
       " ' Adelice',\n",
       " ' Adelina',\n",
       " ' Adelind',\n",
       " ' Adeline',\n",
       " ' Adella',\n",
       " ' Adelle',\n",
       " ' Adena',\n",
       " ' Adey',\n",
       " ' Adi',\n",
       " ' Adiana',\n",
       " ' Adina',\n",
       " ' Adora',\n",
       " ' Adore',\n",
       " ' Adoree',\n",
       " ' Adorne',\n",
       " ' Adrea',\n",
       " ' Adria',\n",
       " ' Adriaens',\n",
       " ' Adrian',\n",
       " ' Adriana',\n",
       " ' Adriane',\n",
       " ' Adrianna',\n",
       " ' Adrianne',\n",
       " ' Adrien',\n",
       " ' Adriena',\n",
       " ' Adrienne',\n",
       " ' Aeriel',\n",
       " ' Aeriela',\n",
       " ' Aeriell',\n",
       " ' Ag',\n",
       " ' Agace',\n",
       " ' Agata',\n",
       " ' Agatha',\n",
       " ' Agathe',\n",
       " ' Aggi',\n",
       " ' Aggie',\n",
       " ' Aggy',\n",
       " ' Agna',\n",
       " ' Agnella',\n",
       " ' Agnes',\n",
       " ' Agnese',\n",
       " ' Agnesse',\n",
       " ' Agneta',\n",
       " ' Agnola',\n",
       " ' Agretha',\n",
       " ' Aida',\n",
       " ' Aidan',\n",
       " ' Aigneis',\n",
       " ' Aila',\n",
       " ' Aile',\n",
       " ' Ailee',\n",
       " ' Aileen',\n",
       " ' Ailene',\n",
       " ' Ailey',\n",
       " ' Aili',\n",
       " ' Ailina',\n",
       " ' Ailyn',\n",
       " ' Aime',\n",
       " ' Aimee',\n",
       " ' Aimil',\n",
       " ' Aina',\n",
       " ' Aindrea',\n",
       " ' Ainslee',\n",
       " ' Ainsley',\n",
       " ' Ainslie',\n",
       " ' Ajay',\n",
       " ' Alaine',\n",
       " ' Alameda',\n",
       " ' Alana',\n",
       " ' Alanah',\n",
       " ' Alane',\n",
       " ' Alanna',\n",
       " ' Alayne',\n",
       " ' Alberta',\n",
       " ' Albertina',\n",
       " ' Albertine',\n",
       " ' Albina',\n",
       " ' Alecia',\n",
       " ' Aleda',\n",
       " ' Aleece',\n",
       " ' Aleecia',\n",
       " ' Aleen',\n",
       " ' Alejandra',\n",
       " ' Alejandrina',\n",
       " ' Alena',\n",
       " ' Alene',\n",
       " ' Alessandra',\n",
       " ' Aleta',\n",
       " ' Alethea',\n",
       " ' Alex',\n",
       " ' Alexa',\n",
       " ' Alexandra',\n",
       " ' Alexandrina',\n",
       " ' Alexi',\n",
       " ' Alexia',\n",
       " ' Alexina',\n",
       " ' Alexine',\n",
       " ' Alexis',\n",
       " ' Alfie',\n",
       " ' Alfreda',\n",
       " ' Ali',\n",
       " ' Alia',\n",
       " ' Alica',\n",
       " ' Alice',\n",
       " ' Alicea',\n",
       " ' Alicia',\n",
       " ' Alida',\n",
       " ' Alidia',\n",
       " ' Alina',\n",
       " ' Aline',\n",
       " ' Alis',\n",
       " ' Alisa',\n",
       " ' Alisha',\n",
       " ' Alison',\n",
       " ' Alissa',\n",
       " ' Alisun',\n",
       " ' Alix',\n",
       " ' Aliza',\n",
       " ' Alla',\n",
       " ' Alleen',\n",
       " ' Allegra',\n",
       " ' Allene',\n",
       " ' Alli',\n",
       " ' Allianora',\n",
       " ' Allie',\n",
       " ' Allina',\n",
       " ' Allis',\n",
       " ' Allison',\n",
       " ' Allissa',\n",
       " ' Allsun',\n",
       " ' Ally',\n",
       " ' Allyce',\n",
       " ' Allyn',\n",
       " ' Allys',\n",
       " ' Allyson',\n",
       " ' Alma',\n",
       " ' Almeda',\n",
       " ' Almeria',\n",
       " ' Almeta',\n",
       " ' Almira',\n",
       " ' Almire',\n",
       " ' Aloise',\n",
       " ' Aloisia',\n",
       " ' Aloysia',\n",
       " ' Alpa',\n",
       " ' Alta',\n",
       " ' Althea',\n",
       " ' Alvera',\n",
       " ' Alvina',\n",
       " ' Alvinia',\n",
       " ' Alvira',\n",
       " ' Alyce',\n",
       " ' Alyda',\n",
       " ' Alys',\n",
       " ' Alysa',\n",
       " ' Alyse',\n",
       " ' Alysia',\n",
       " ' Alyson',\n",
       " ' Alyss',\n",
       " ' Alyssa',\n",
       " ' Amabel',\n",
       " ' Amabelle',\n",
       " ' Amalea',\n",
       " ' Amalee',\n",
       " ' Amaleta',\n",
       " ' Amalia',\n",
       " ' Amalie',\n",
       " ' Amalita',\n",
       " ' Amalle',\n",
       " ' Amanda',\n",
       " ' Amandi',\n",
       " ' Amandie',\n",
       " ' Amandy',\n",
       " ' Amara',\n",
       " ' Amargo',\n",
       " ' Amata',\n",
       " ' Amber',\n",
       " ' Amberly',\n",
       " ' Ambrosia',\n",
       " ' Ambur',\n",
       " ' Ame',\n",
       " ' Amelia',\n",
       " ' Amelie',\n",
       " ' Amelina',\n",
       " ' Ameline',\n",
       " ' Amelita',\n",
       " ' Ami',\n",
       " ' Amie',\n",
       " ' Amity',\n",
       " ' Ammamaria',\n",
       " ' Amy',\n",
       " ' Ana',\n",
       " ' Anabel',\n",
       " ' Anabella',\n",
       " ' Anabelle',\n",
       " ' Anais',\n",
       " ' Analiese',\n",
       " ' Analise',\n",
       " ' Anallese',\n",
       " ' Anallise',\n",
       " ' Anastasia',\n",
       " ' Anastasie',\n",
       " ' Anastassia',\n",
       " ' Anatola',\n",
       " ' Andee',\n",
       " ' Andi',\n",
       " ' Andie',\n",
       " ' Andra',\n",
       " ' Andrea',\n",
       " ' Andreana',\n",
       " ' Andree',\n",
       " ' Andrei',\n",
       " ' Andria',\n",
       " ' Andriana',\n",
       " ' Andriette',\n",
       " ' Andromache',\n",
       " ' Andromeda',\n",
       " ' Andy',\n",
       " ' Anestassia',\n",
       " ' Anet',\n",
       " ' Anett',\n",
       " ' Anetta',\n",
       " ' Anette',\n",
       " ' Ange',\n",
       " ' Angel',\n",
       " ' Angela',\n",
       " ' Angele',\n",
       " ' Angelia',\n",
       " ' Angelica',\n",
       " ' Angelika',\n",
       " ' Angelina',\n",
       " ' Angeline',\n",
       " ' Angelique',\n",
       " ' Angelita',\n",
       " ' Angelle',\n",
       " ' Angie',\n",
       " ' Angil',\n",
       " ' Angy',\n",
       " ' Ania',\n",
       " ' Anica',\n",
       " ' Anissa',\n",
       " ' Anita',\n",
       " ' Anitra',\n",
       " ' Anja',\n",
       " ' Anjanette',\n",
       " ' Anjela',\n",
       " ' Ann',\n",
       " ' Ann-Mari',\n",
       " ' Ann-Marie',\n",
       " ' Anna',\n",
       " ' Anna-Diana',\n",
       " ' Anna-Diane',\n",
       " ' Anna-Maria',\n",
       " ' Annabal',\n",
       " ' Annabel',\n",
       " ' Annabela',\n",
       " ' Annabell',\n",
       " ' Annabella',\n",
       " ' Annabelle',\n",
       " ' Annadiana',\n",
       " ' Annadiane',\n",
       " ' Annalee',\n",
       " ' Annalena',\n",
       " ' Annaliese',\n",
       " ' Annalisa',\n",
       " ' Annalise',\n",
       " ' Annalyse',\n",
       " ' Annamari',\n",
       " ' Annamaria',\n",
       " ' Annamarie',\n",
       " ' Anne',\n",
       " ' Anne-Corinne',\n",
       " ' Anne-Mar',\n",
       " ' Anne-Marie',\n",
       " ' Annecorinne',\n",
       " ' Anneliese',\n",
       " ' Annelise',\n",
       " ' Annemarie',\n",
       " ' Annetta',\n",
       " ' Annette',\n",
       " ' Anni',\n",
       " ' Annice',\n",
       " ' Annie',\n",
       " ' Annissa',\n",
       " ' Annmaria',\n",
       " ' Annmarie',\n",
       " ' Annnora',\n",
       " ' Annora',\n",
       " ' Anny',\n",
       " ' Anselma',\n",
       " ' Ansley',\n",
       " ' Anstice',\n",
       " ' Anthe',\n",
       " ' Anthea',\n",
       " ' Anthia',\n",
       " ' Antoinette',\n",
       " ' Antonella',\n",
       " ' Antonetta',\n",
       " ' Antonia',\n",
       " ' Antonie',\n",
       " ' Antonietta',\n",
       " ' Antonina',\n",
       " ' Anya',\n",
       " ' Aphrodite',\n",
       " ' Appolonia',\n",
       " ' April',\n",
       " ' Aprilette',\n",
       " ' Ara',\n",
       " ' Arabel',\n",
       " ' Arabela',\n",
       " ' Arabele',\n",
       " ' Arabella',\n",
       " ' Arabelle',\n",
       " ' Arda',\n",
       " ' Ardath',\n",
       " ' Ardeen',\n",
       " ' Ardelia',\n",
       " ' Ardelis',\n",
       " ' Ardella',\n",
       " ' Ardelle',\n",
       " ' Arden',\n",
       " ' Ardene',\n",
       " ' Ardenia',\n",
       " ' Ardine',\n",
       " ' Ardis',\n",
       " ' Ardith',\n",
       " ' Ardra',\n",
       " ' Ardyce',\n",
       " ' Ardys',\n",
       " ' Ardyth',\n",
       " ' Aretha',\n",
       " ' Ariadne',\n",
       " ' Ariana',\n",
       " ' Arianne',\n",
       " ' Aridatha',\n",
       " ' Ariel',\n",
       " ' Ariela',\n",
       " ' Ariella',\n",
       " ' Arielle',\n",
       " ' Arlana',\n",
       " ' Arlee',\n",
       " ' Arleen',\n",
       " ' Arlen',\n",
       " ' Arlena',\n",
       " ' Arlene',\n",
       " ' Arleta',\n",
       " ' Arlette',\n",
       " ' Arleyne',\n",
       " ' Arlie',\n",
       " ' Arliene',\n",
       " ' Arlina',\n",
       " ' Arlinda',\n",
       " ' Arline',\n",
       " ' Arly',\n",
       " ' Arlyn',\n",
       " ' Arlyne',\n",
       " ' Aryn',\n",
       " ' Ashely',\n",
       " ' Ashlee',\n",
       " ' Ashleigh',\n",
       " ' Ashlen',\n",
       " ' Ashley',\n",
       " ' Ashli',\n",
       " ' Ashlie',\n",
       " ' Ashly',\n",
       " ' Asia',\n",
       " ' Astra',\n",
       " ' Astrid',\n",
       " ' Astrix',\n",
       " ' Atalanta',\n",
       " ' Athena',\n",
       " ' Athene',\n",
       " ' Atlanta',\n",
       " ' Atlante',\n",
       " ' Auberta',\n",
       " ' Aubine',\n",
       " ' Aubree',\n",
       " ' Aubrette',\n",
       " ' Aubrey',\n",
       " ' Aubrie',\n",
       " ' Aubry',\n",
       " ' Audi',\n",
       " ' Audie',\n",
       " ' Audra',\n",
       " ' Audre',\n",
       " ' Audrey',\n",
       " ' Audrie',\n",
       " ' Audry',\n",
       " ' Audrye',\n",
       " ' Audy',\n",
       " ' Augusta',\n",
       " ' Auguste',\n",
       " ' Augustina',\n",
       " ' Augustine',\n",
       " ' Aura',\n",
       " ' Aurea',\n",
       " ' Aurel',\n",
       " ' Aurelea',\n",
       " ' Aurelia',\n",
       " ' Aurelie',\n",
       " ' Auria',\n",
       " ' Aurie',\n",
       " ' Aurilia',\n",
       " ' Aurlie',\n",
       " ' Auroora',\n",
       " ' Aurora',\n",
       " ' Aurore',\n",
       " ' Austin',\n",
       " ' Austina',\n",
       " ' Austine',\n",
       " ' Ava',\n",
       " ' Aveline',\n",
       " ' Averil',\n",
       " ' Averyl',\n",
       " ' Avie',\n",
       " ' Avis',\n",
       " ' Aviva',\n",
       " ' Avivah',\n",
       " ' Avril',\n",
       " ' Avrit',\n",
       " ' Ayn',\n",
       " ' Bab',\n",
       " ' Babara',\n",
       " ' Babette',\n",
       " ' Babita',\n",
       " ' Babs',\n",
       " ' Bambi',\n",
       " ' Bambie',\n",
       " ' Bamby',\n",
       " ' Barb',\n",
       " ' Barbabra',\n",
       " ' Barbara',\n",
       " ' Barbara-Anne',\n",
       " ' Barbaraanne',\n",
       " ' Barbe',\n",
       " ' Barbee',\n",
       " ' Barbette',\n",
       " ' Barbey',\n",
       " ' Barbi',\n",
       " ' Barbie',\n",
       " ' Barbra',\n",
       " ' Barby',\n",
       " ' Bari',\n",
       " ' Barrie',\n",
       " ' Barry',\n",
       " ' Basia',\n",
       " ' Bathsheba',\n",
       " ' Batsheva',\n",
       " ' Bea',\n",
       " ' Beatrice',\n",
       " ' Beatrisa',\n",
       " ' Beatrix',\n",
       " ' Beatriz',\n",
       " ' Beau',\n",
       " ' Bebe',\n",
       " ' Becca',\n",
       " ' Becka',\n",
       " ' Becki',\n",
       " ' Beckie',\n",
       " ' Becky',\n",
       " ' Bee',\n",
       " ' Beilul',\n",
       " ' Beitris',\n",
       " ' Bekki',\n",
       " ' Bel',\n",
       " ' Belia',\n",
       " ' Belicia',\n",
       " ' Belinda',\n",
       " ' Belita',\n",
       " ' Bell',\n",
       " ' Bella',\n",
       " ' Bellamy',\n",
       " ' Bellanca',\n",
       " ' Belle',\n",
       " ' Bellina',\n",
       " ' Belva',\n",
       " ' Belvia',\n",
       " ' Bendite',\n",
       " ' Benedetta',\n",
       " ' Benedicta',\n",
       " ' Benedikta',\n",
       " ' Benetta',\n",
       " ' Benita',\n",
       " ' Benni',\n",
       " ' Bennie',\n",
       " ' Benny',\n",
       " ' Benoite',\n",
       " ' Berenice',\n",
       " ' Beret',\n",
       " ' Berget',\n",
       " ' Berna',\n",
       " ' Bernadene',\n",
       " ' Bernadette',\n",
       " ' Bernadina',\n",
       " ' Bernadine',\n",
       " ' Bernardina',\n",
       " ' Bernardine',\n",
       " ' Bernelle',\n",
       " ' Bernete',\n",
       " ' Bernetta',\n",
       " ' Bernette',\n",
       " ' Berni',\n",
       " ' Bernice',\n",
       " ' Bernie',\n",
       " ' Bernita',\n",
       " ' Berny',\n",
       " ' Berri',\n",
       " ' Berrie',\n",
       " ' Berry',\n",
       " ' Bert',\n",
       " ' Berta',\n",
       " ' Berte',\n",
       " ' Bertha',\n",
       " ' Berthe',\n",
       " ' Berti',\n",
       " ' Bertie',\n",
       " ' Bertina',\n",
       " ' Bertine',\n",
       " ' Berty',\n",
       " ' Beryl',\n",
       " ' Beryle',\n",
       " ' Bess',\n",
       " ' Bessie',\n",
       " ' Bessy',\n",
       " ' Beth',\n",
       " ' Bethanne',\n",
       " ' Bethany',\n",
       " ' Bethena',\n",
       " ' Bethina',\n",
       " ' Betsey',\n",
       " ' Betsy',\n",
       " ' Betta',\n",
       " ' Bette',\n",
       " ' Bette-Ann',\n",
       " ' Betteann',\n",
       " ' Betteanne',\n",
       " ' Betti',\n",
       " ' Bettie',\n",
       " ' Bettina',\n",
       " ' Bettine',\n",
       " ' Betty',\n",
       " ' Bettye',\n",
       " ' Beulah',\n",
       " ' Bev',\n",
       " ' Beverie',\n",
       " ' Beverlee',\n",
       " ' Beverlie',\n",
       " ' Beverly',\n",
       " ' Bevvy',\n",
       " ' Bianca',\n",
       " ' Bianka',\n",
       " ' Biddy',\n",
       " ' Bidget',\n",
       " ' Bill',\n",
       " ' Billi',\n",
       " ' Billie',\n",
       " ' Billy',\n",
       " ' Binni',\n",
       " ' Binnie',\n",
       " ' Binny',\n",
       " ' Bird',\n",
       " ' Birdie',\n",
       " ' Birgit',\n",
       " ' Birgitta',\n",
       " ' Blair',\n",
       " ' Blaire',\n",
       " ' Blake',\n",
       " ' Blakelee',\n",
       " ' Blakeley',\n",
       " ' Blanca',\n",
       " ' Blanch',\n",
       " ' Blancha',\n",
       " ' Blanche',\n",
       " ' Blinni',\n",
       " ' Blinnie',\n",
       " ' Blinny',\n",
       " ' Bliss',\n",
       " ' Blisse',\n",
       " ' Blithe',\n",
       " ' Blondell',\n",
       " ' Blondelle',\n",
       " ' Blondie',\n",
       " ' Blondy',\n",
       " ' Blythe',\n",
       " ' Bo',\n",
       " ' Bobbette',\n",
       " ' Bobbi',\n",
       " ' Bobbie',\n",
       " ' Bobby',\n",
       " ' Bobette',\n",
       " ' Bobina',\n",
       " ' Bobine',\n",
       " ' Bobinette',\n",
       " ' Bonita',\n",
       " ' Bonnee',\n",
       " ' Bonni',\n",
       " ' Bonnie',\n",
       " ' Bonny',\n",
       " ' Brana',\n",
       " ' Brandais',\n",
       " ' Brande',\n",
       " ' Brandea',\n",
       " ' Brandi',\n",
       " ' Brandice',\n",
       " ' Brandie',\n",
       " ' Brandise',\n",
       " ' Brandy',\n",
       " ' Brea',\n",
       " ' Breanne',\n",
       " ' Brear',\n",
       " ' Bree',\n",
       " ' Breena',\n",
       " ' Bren',\n",
       " ' Brena',\n",
       " ' Brenda',\n",
       " ' Brenn',\n",
       " ' Brenna',\n",
       " ' Brett',\n",
       " ' Bria',\n",
       " ' Briana',\n",
       " ' Brianna',\n",
       " ' Brianne',\n",
       " ' Bride',\n",
       " ' Bridget',\n",
       " ' Bridgett',\n",
       " ' Bridgette',\n",
       " ' Bridie',\n",
       " ' Brier',\n",
       " ' Brietta',\n",
       " ' Brigid',\n",
       " ' Brigida',\n",
       " ' Brigit',\n",
       " ' Brigitta',\n",
       " ' Brigitte',\n",
       " ' Brina',\n",
       " ' Briney',\n",
       " ' Briny',\n",
       " ' Brit',\n",
       " ' Brita',\n",
       " ' Britaney',\n",
       " ' Britani',\n",
       " ' Briteny',\n",
       " ' Britney',\n",
       " ' Britni',\n",
       " ' Britt',\n",
       " ' Britta',\n",
       " ' Brittan',\n",
       " ' Brittany',\n",
       " ' Britte',\n",
       " ' Brittney',\n",
       " ' Brook',\n",
       " ' Brooke',\n",
       " ' Brooks',\n",
       " ' Brunella',\n",
       " ' Brunhilda',\n",
       " ' Brunhilde',\n",
       " ' Bryana',\n",
       " ' Bryn',\n",
       " ' Bryna',\n",
       " ' Brynn',\n",
       " ' Brynna',\n",
       " ' Brynne',\n",
       " ' Buffy',\n",
       " ' Bunni',\n",
       " ' Bunnie',\n",
       " ' Bunny',\n",
       " ' Burta',\n",
       " ' Cabrina',\n",
       " ' Cacilia',\n",
       " ' Cacilie',\n",
       " ' Caitlin',\n",
       " ' Caitrin',\n",
       " ' Cal',\n",
       " ' Calida',\n",
       " ' Calla',\n",
       " ' Calley',\n",
       " ' Calli',\n",
       " ' Callida',\n",
       " ' Callie',\n",
       " ' Cally',\n",
       " ' Calypso',\n",
       " ' Cam',\n",
       " ' Camala',\n",
       " ' Camel',\n",
       " ' Camella',\n",
       " ' Camellia',\n",
       " ' Cameo',\n",
       " ' Cami',\n",
       " ' Camila',\n",
       " ' Camile',\n",
       " ' Camilla',\n",
       " ' Camille',\n",
       " ' Cammi',\n",
       " ' Cammie',\n",
       " ' Cammy',\n",
       " ' Canada',\n",
       " ' Candace',\n",
       " ' Candi',\n",
       " ' Candice',\n",
       " ' Candida',\n",
       " ' Candide',\n",
       " ' Candie',\n",
       " ' Candis',\n",
       " ' Candra',\n",
       " ' Candy',\n",
       " ' Cappella',\n",
       " ' Caprice',\n",
       " ' Cara',\n",
       " ' Caralie',\n",
       " ' Caren',\n",
       " ' Carena',\n",
       " ' Caresa',\n",
       " ' Caressa',\n",
       " ' Caresse',\n",
       " ' Carey',\n",
       " ' Cari',\n",
       " ' Caria',\n",
       " ' Carie',\n",
       " ' Caril',\n",
       " ' Carilyn',\n",
       " ' Carin',\n",
       " ' Carina',\n",
       " ' Carine',\n",
       " ' Cariotta',\n",
       " ' Carissa',\n",
       " ' Carita',\n",
       " ' Caritta',\n",
       " ' Carla',\n",
       " ' Carlee',\n",
       " ' Carleen',\n",
       " ' Carlen',\n",
       " ' Carlena',\n",
       " ' Carlene',\n",
       " ' Carley',\n",
       " ' Carli',\n",
       " ' Carlie',\n",
       " ' Carlin',\n",
       " ' Carlina',\n",
       " ' Carline',\n",
       " ' Carlisle',\n",
       " ' Carlita',\n",
       " ' Carlota',\n",
       " ' Carlotta',\n",
       " ' Carly',\n",
       " ' Carlye',\n",
       " ' Carlyn',\n",
       " ' Carlynn',\n",
       " ' Carlynne',\n",
       " ' Carma',\n",
       " ' Carmel',\n",
       " ' Carmela',\n",
       " ' Carmelia',\n",
       " ' Carmelina',\n",
       " ' Carmelita',\n",
       " ' Carmella',\n",
       " ' Carmelle',\n",
       " ' Carmen',\n",
       " ' Carmina',\n",
       " ' Carmine',\n",
       " ' Carmita',\n",
       " ' Carmon',\n",
       " ' Caro',\n",
       " ' Carol',\n",
       " ' Carol-Jean',\n",
       " ' Carola',\n",
       " ' Carolan',\n",
       " ' Carolann',\n",
       " ' Carole',\n",
       " ' Carolee',\n",
       " ' Caroleen',\n",
       " ' Carolie',\n",
       " ' Carolin',\n",
       " ' Carolina',\n",
       " ' Caroline',\n",
       " ' Caroljean',\n",
       " ' Carolyn',\n",
       " ' Carolyne',\n",
       " ' Carolynn',\n",
       " ' Caron',\n",
       " ' Carree',\n",
       " ' Carri',\n",
       " ' Carrie',\n",
       " ' Carrissa',\n",
       " ' Carrol',\n",
       " ' Carroll',\n",
       " ' Carry',\n",
       " ' Cary',\n",
       " ' Caryl',\n",
       " ' Caryn',\n",
       " ' Casandra',\n",
       " ' Casey',\n",
       " ' Casi',\n",
       " ' Casia',\n",
       " ' Casie',\n",
       " ' Cass',\n",
       " ' Cassandra',\n",
       " ' Cassandre',\n",
       " ' Cassandry',\n",
       " ' Cassaundra',\n",
       " ' Cassey',\n",
       " ' Cassi',\n",
       " ' Cassie',\n",
       " ' Cassondra',\n",
       " ' Cassy',\n",
       " ' Cat',\n",
       " ' Catarina',\n",
       " ' Cate',\n",
       " ' Caterina',\n",
       " ' Catha',\n",
       " ' Catharina',\n",
       " ' Catharine',\n",
       " ' Cathe',\n",
       " ' Cathee',\n",
       " ' Catherin',\n",
       " ' Catherina',\n",
       " ' Catherine',\n",
       " ' Cathi',\n",
       " ' Cathie',\n",
       " ' Cathleen',\n",
       " ' Cathlene',\n",
       " ' Cathrin',\n",
       " ' Cathrine',\n",
       " ' Cathryn',\n",
       " ' Cathy',\n",
       " ' Cathyleen',\n",
       " ' Cati',\n",
       " ' Catie',\n",
       " ' Catina',\n",
       " ' Catlaina',\n",
       " ' Catlee',\n",
       " ' Catlin',\n",
       " ' Catrina',\n",
       " ' Catriona',\n",
       " ' Caty',\n",
       " ' Cayla',\n",
       " ' Cecelia',\n",
       " ' Cecil',\n",
       " ' Cecile',\n",
       " ' Ceciley',\n",
       " ' Cecilia',\n",
       " ' Cecilla',\n",
       " ' Cecily',\n",
       " ' Ceil',\n",
       " ' Cele',\n",
       " ' Celene',\n",
       " ' Celesta',\n",
       " ' Celeste',\n",
       " ' Celestia',\n",
       " ' Celestina',\n",
       " ' Celestine',\n",
       " ' Celestyn',\n",
       " ' Celestyna',\n",
       " ' Celia',\n",
       " ' Celie',\n",
       " ' Celina',\n",
       " ' Celinda',\n",
       " ' Celine',\n",
       " ' Celinka',\n",
       " ' Celisse',\n",
       " ' Celle',\n",
       " ' Cesya',\n",
       " ' Chad',\n",
       " ' Chanda',\n",
       " ' Chandal',\n",
       " ' Chandra',\n",
       " ' Channa',\n",
       " ' Chantal',\n",
       " ' Chantalle',\n",
       " ' Charil',\n",
       " ' Charin',\n",
       " ' Charis',\n",
       " ' Charissa',\n",
       " ' Charisse',\n",
       " ' Charita',\n",
       " ' Charity',\n",
       " ' Charla',\n",
       " ' Charlean',\n",
       " ' Charleen',\n",
       " ' Charlena',\n",
       " ' Charlene',\n",
       " ' Charline',\n",
       " ' Charlot',\n",
       " ' Charlott',\n",
       " ' Charlotta',\n",
       " ' Charlotte',\n",
       " ' Charmain',\n",
       " ' Charmaine',\n",
       " ' Charmane',\n",
       " ' Charmian',\n",
       " ' Charmine',\n",
       " ' Charmion',\n",
       " ' Charo',\n",
       " ' Charyl',\n",
       " ' Chastity',\n",
       " ' Chelsae',\n",
       " ' Chelsea',\n",
       " ' Chelsey',\n",
       " ' Chelsie',\n",
       " ' Chelsy',\n",
       " ' Cher',\n",
       " ' Chere',\n",
       " ' Cherey',\n",
       " ' Cheri',\n",
       " ' Cherianne',\n",
       " ' Cherice',\n",
       " ' Cherida',\n",
       " ' Cherie',\n",
       " ' Cherilyn',\n",
       " ' Cherilynn',\n",
       " ' Cherin',\n",
       " ' Cherise',\n",
       " ' Cherish',\n",
       " ' Cherlyn',\n",
       " ' Cherri',\n",
       " ' Cherrita',\n",
       " ' Cherry',\n",
       " ' Chery',\n",
       " ' Cherye',\n",
       " ' Cheryl',\n",
       " ' Cheslie',\n",
       " ' Chiarra',\n",
       " ' Chickie',\n",
       " ' Chicky',\n",
       " ' Chiquita',\n",
       " ' Chloe',\n",
       " ' Chloette',\n",
       " ' Chloris',\n",
       " ' Chris',\n",
       " ' Chriss',\n",
       " ' Chrissa',\n",
       " ' Chrissie',\n",
       " ' Chrissy',\n",
       " ' Christa',\n",
       " ' Christabel',\n",
       " ' Christabella',\n",
       " ' Christabelle',\n",
       " ' Christal',\n",
       " ' Christalle',\n",
       " ' Christan',\n",
       " ' Christean',\n",
       " ' Christel',\n",
       " ' Christen',\n",
       " ' Christi',\n",
       " ' Christian',\n",
       " ' Christiana',\n",
       " ' Christiane',\n",
       " ' Christie',\n",
       " ' Christin',\n",
       " ' Christina',\n",
       " ' Christine',\n",
       " ' Christy',\n",
       " ' Christyna',\n",
       " ' Chrysa',\n",
       " ' Chrysler',\n",
       " ' Chrystal',\n",
       " ' Chryste',\n",
       " ' Chrystel',\n",
       " ' Ciara',\n",
       " ' Cicely',\n",
       " ' Cicily',\n",
       " ' Ciel',\n",
       " ' Cilka',\n",
       " ' Cinda',\n",
       " ' Cindee',\n",
       " ' Cindelyn',\n",
       " ' Cinderella',\n",
       " ' Cindi',\n",
       " ' Cindie',\n",
       " ' Cindra',\n",
       " ' Cindy',\n",
       " ' Cinnamon',\n",
       " ' Cissie',\n",
       " ' Cissy',\n",
       " ' Clair',\n",
       " ' Claire',\n",
       " ' Clara',\n",
       " ' Clarabelle',\n",
       " ' Clare',\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(''.join(names)))\n",
    "tokens.append(pad_token) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id = dict([(tokens[i], i) for i in range(n_tokens)]) ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[16 20 36 29 46 29 21 38 55]\n",
      " [16 34 38  4 47 30 55 55 55]\n",
      " [16 18 47 33 48 48 33 21 55]\n",
      " [16 34 33  4 22 29 17 17 21]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    }
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='relu') ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1) ### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    }
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix,predictions_matrix))### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    }
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Roleneke\n",
      " Afcelnel\n",
      " Azjaneice\n",
      " Niuy\n",
      " Annca\n",
      " Anlry\n",
      " Onaeaned\n",
      " Mailie\n",
      " Jinplereh\n",
      " Laa\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpelee\n",
      " Trumpa\n",
      " Trump\n",
      " Trumpe\n",
      " Trumpale\n",
      " Trumpel\n",
      " Trumpen\n",
      " Trumpan\n",
      " Trumpes\n",
      " Trumpe\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    }
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"FJ7CtA3sdvs3ZSk6\"\n",
    "COURSERA_EMAIL = \"e0767618@u.nus.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ee1c64ea2a45669a8414a8818b84fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/haoyuzhu/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/haoyuzhu/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7fe02143a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7fe02143a350>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7fe02143a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7fe02143a350>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-79-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Operation 'rnn_2/while/IsVariableInitialized' has been marked as not fetchable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-62766a2145fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_num_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;31m# framework.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;31m# Handle Keras mask propagation from previous layer to current layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[1;32m    246\u001b[0m           layer_inputs, processed_ops, created_layers)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 879\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1158\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       raise ValueError(\n\u001b[0;32m--> 500\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'rnn_2/while/IsVariableInitialized' has been marked as not fetchable."
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
